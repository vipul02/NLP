{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"Count how many times each unique word occurs in text.\"\"\"\n",
    "    counts = dict()  # dictionary of { <word>: <count> } pairs to return\n",
    "    \n",
    "    text = text.lower()\n",
    "#     text = re.sub(r'\\W', ' ', text)\n",
    "#     words = re.findall(r'\\w+', text)\n",
    "    words = re.split(r'\\W+', text)\n",
    "    for word in words:\n",
    "        if word != \"\":\n",
    "            if word not in counts:\n",
    "                counts[word] = 1\n",
    "            else:\n",
    "                counts[word] += 1\n",
    "    \n",
    "    return counts\n",
    "\n",
    "\n",
    "def test_run():\n",
    "    with open(\"input.txt\", \"r\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "        counts = count_words(text)\n",
    "        sorted_counts = sorted(counts.items(), key=lambda pair: pair[1], reverse=True)\n",
    "        \n",
    "        print(\"10 most common words:\\nWord\\tCount\")\n",
    "        for word, count in sorted_counts[:10]:\n",
    "            print(\"{}\\t{}\".format(word, count))\n",
    "        \n",
    "        print(\"\\n10 least common words:\\nWord\\tCount\")\n",
    "        for word, count in sorted_counts[-10:]:\n",
    "            print(\"{}\\t{}\".format(word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most common words:\n",
      "Word\tCount\n",
      "a\t9\n",
      "he\t6\n",
      "the\t6\n",
      "and\t5\n",
      "as\t4\n",
      "was\t4\n",
      "with\t3\n",
      "i\t2\n",
      "of\t2\n",
      "his\t2\n",
      "\n",
      "10 least common words:\n",
      "Word\tCount\n",
      "tables\t1\n",
      "merry\t1\n",
      "word\t1\n",
      "or\t1\n",
      "slap\t1\n",
      "on\t1\n",
      "for\t1\n",
      "more\t1\n",
      "favoured\t1\n",
      "guests\t1\n"
     ]
    }
   ],
   "source": [
    "test_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sent_tokenize(text):\n",
    "    \"\"\"Split text into sentences.\"\"\"\n",
    "    \n",
    "    # TODO: Split text by sentence delimiters (remove delimiters)\n",
    "    sentences = re.split(r'\\.|\\?', text)\n",
    "    \n",
    "    # TODO: Remove leading and trailing spaces from each sentence\n",
    "    sentences = list(map(lambda x: x.strip(), sentences))\n",
    "    \n",
    "    # TODO: Return a list of sentences (remove blank strings)\n",
    "    sentences_ = []\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 0:\n",
    "            sentences_.append(sentence)\n",
    "    \n",
    "    return sentences_\n",
    "\n",
    "\n",
    "def word_tokenize(sent):\n",
    "    \"\"\"Split a sentence into words.\"\"\"\n",
    "    \n",
    "    # TODO: Split sent by word delimiters (remove delimiters)\n",
    "    words = re.split(r'\\W+', sent)\n",
    "    \n",
    "    # TODO: Remove leading and trailing spaces from each word\n",
    "    words = list(map(lambda x: x.strip(), words))\n",
    "    \n",
    "    # TODO: Return a list of words (remove blank strings)\n",
    "    words_ = []\n",
    "    for word in words:\n",
    "        if len(word) > 0:\n",
    "            words_.append(sentence)\n",
    "    \n",
    "    return sentences_\n",
    "\n",
    "\n",
    "def test_run():\n",
    "    \"\"\"Called on Test Run.\"\"\"\n",
    "\n",
    "    text = \"The first time you see The Second Renaissance it may look boring. Look at it at least twice and definitely watch part 2. It will change your view of the matrix. Are the human people the ones who started the war? Is AI a bad thing?\"\n",
    "    print(\"--- Sample text ---\", text, sep=\"\\n\")\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    print(\"\\n--- Sentences ---\")\n",
    "    print(sentences)\n",
    "    \n",
    "    print(\"\\n--- Words ---\")\n",
    "    for sent in sentences:\n",
    "        print(sent)\n",
    "        print(word_tokenize(sent))\n",
    "        print()  # blank line for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The first time you see The Second Renaissance it may look boring',\n",
       " ' Look at it at least twice and definitely watch part 2',\n",
       " ' It will change your view of the matrix',\n",
       " ' Are the human people the ones who started the war',\n",
       " ' Is AI a bad thing',\n",
       " '']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'\\.|\\?', \"The first time you see The Second Renaissance it may look boring. Look at it at least twice and definitely watch part 2. It will change your view of the matrix. Are the human people the ones who started the war? Is AI a bad thing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The first time you see The Second Renaissance it may look boring',\n",
       " 'Look at it at least twice and definitely watch part 2',\n",
       " 'It will change your view of the matrix',\n",
       " 'Are the human people the ones who started the war',\n",
       " 'Is AI a bad thing',\n",
       " None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: strip_rm(x), _))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-e0924142b84b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-e0924142b84b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    list(map(lambda x: x if len(x) == 0 else pass, _))\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
